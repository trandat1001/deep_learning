{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "0    768 non-null int64\n",
      "1    768 non-null int64\n",
      "2    768 non-null int64\n",
      "3    768 non-null int64\n",
      "4    768 non-null int64\n",
      "5    768 non-null float64\n",
      "6    768 non-null float64\n",
      "7    768 non-null int64\n",
      "8    768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/pima-indians-diabetes.csv\", header=None)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,:8]\n",
    "y = dataset.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dat-tran/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/dat-tran/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/dat-tran/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/dat-tran/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=512, kernel_initializer='uniform', activation='relu', input_dim=8))\n",
    "classifier.add(Dense(units=64, kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 491 samples, validate on 123 samples\n",
      "Epoch 1/100\n",
      "491/491 [==============================] - 1s 1ms/step - loss: 0.6604 - acc: 0.6884 - val_loss: 0.5951 - val_acc: 0.7480\n",
      "Epoch 2/100\n",
      "491/491 [==============================] - 0s 270us/step - loss: 0.5226 - acc: 0.7678 - val_loss: 0.4951 - val_acc: 0.7561\n",
      "Epoch 3/100\n",
      "491/491 [==============================] - 0s 267us/step - loss: 0.4585 - acc: 0.7902 - val_loss: 0.4922 - val_acc: 0.7561\n",
      "Epoch 4/100\n",
      "491/491 [==============================] - 0s 280us/step - loss: 0.4449 - acc: 0.7902 - val_loss: 0.4957 - val_acc: 0.7398\n",
      "Epoch 5/100\n",
      "491/491 [==============================] - 0s 279us/step - loss: 0.4363 - acc: 0.7923 - val_loss: 0.5078 - val_acc: 0.7236\n",
      "Epoch 6/100\n",
      "491/491 [==============================] - 0s 273us/step - loss: 0.4251 - acc: 0.8045 - val_loss: 0.5098 - val_acc: 0.7398\n",
      "Epoch 7/100\n",
      "491/491 [==============================] - 0s 244us/step - loss: 0.4189 - acc: 0.8065 - val_loss: 0.5138 - val_acc: 0.7236\n",
      "Epoch 8/100\n",
      "491/491 [==============================] - 0s 222us/step - loss: 0.4145 - acc: 0.8147 - val_loss: 0.5207 - val_acc: 0.7236\n",
      "Epoch 9/100\n",
      "491/491 [==============================] - 0s 262us/step - loss: 0.4104 - acc: 0.8208 - val_loss: 0.5316 - val_acc: 0.7236\n",
      "Epoch 10/100\n",
      "491/491 [==============================] - 0s 260us/step - loss: 0.4029 - acc: 0.8147 - val_loss: 0.5321 - val_acc: 0.7398\n",
      "Epoch 11/100\n",
      "491/491 [==============================] - 0s 263us/step - loss: 0.4021 - acc: 0.8147 - val_loss: 0.5374 - val_acc: 0.7236\n",
      "Epoch 12/100\n",
      "491/491 [==============================] - 0s 261us/step - loss: 0.3955 - acc: 0.8269 - val_loss: 0.5319 - val_acc: 0.7236\n",
      "Epoch 13/100\n",
      "491/491 [==============================] - 0s 270us/step - loss: 0.3920 - acc: 0.8269 - val_loss: 0.5267 - val_acc: 0.7317\n",
      "Epoch 14/100\n",
      "491/491 [==============================] - 0s 269us/step - loss: 0.3874 - acc: 0.8411 - val_loss: 0.5321 - val_acc: 0.7073\n",
      "Epoch 15/100\n",
      "491/491 [==============================] - 0s 264us/step - loss: 0.3875 - acc: 0.8310 - val_loss: 0.5443 - val_acc: 0.7073\n",
      "Epoch 16/100\n",
      "491/491 [==============================] - 0s 286us/step - loss: 0.3973 - acc: 0.8187 - val_loss: 0.5347 - val_acc: 0.7398\n",
      "Epoch 17/100\n",
      "491/491 [==============================] - 0s 272us/step - loss: 0.3816 - acc: 0.8350 - val_loss: 0.5593 - val_acc: 0.7154\n",
      "Epoch 18/100\n",
      "491/491 [==============================] - 0s 277us/step - loss: 0.3742 - acc: 0.8452 - val_loss: 0.5248 - val_acc: 0.7236\n",
      "Epoch 19/100\n",
      "491/491 [==============================] - 0s 303us/step - loss: 0.3721 - acc: 0.8391 - val_loss: 0.5469 - val_acc: 0.7398\n",
      "Epoch 20/100\n",
      "491/491 [==============================] - 0s 257us/step - loss: 0.3731 - acc: 0.8432 - val_loss: 0.5385 - val_acc: 0.7073\n",
      "Epoch 21/100\n",
      "491/491 [==============================] - 0s 271us/step - loss: 0.3659 - acc: 0.8473 - val_loss: 0.5677 - val_acc: 0.7073\n",
      "Epoch 22/100\n",
      "491/491 [==============================] - 0s 265us/step - loss: 0.3667 - acc: 0.8432 - val_loss: 0.5830 - val_acc: 0.7236\n",
      "Epoch 23/100\n",
      "491/491 [==============================] - 0s 258us/step - loss: 0.3576 - acc: 0.8554 - val_loss: 0.5464 - val_acc: 0.7236\n",
      "Epoch 24/100\n",
      "491/491 [==============================] - 0s 305us/step - loss: 0.3522 - acc: 0.8513 - val_loss: 0.5804 - val_acc: 0.7154\n",
      "Epoch 25/100\n",
      "491/491 [==============================] - 0s 294us/step - loss: 0.3551 - acc: 0.8493 - val_loss: 0.5799 - val_acc: 0.7236\n",
      "Epoch 26/100\n",
      "491/491 [==============================] - 0s 275us/step - loss: 0.3512 - acc: 0.8574 - val_loss: 0.5418 - val_acc: 0.7073\n",
      "Epoch 27/100\n",
      "491/491 [==============================] - 0s 299us/step - loss: 0.3598 - acc: 0.8473 - val_loss: 0.6070 - val_acc: 0.6992\n",
      "Epoch 28/100\n",
      "491/491 [==============================] - 0s 279us/step - loss: 0.3419 - acc: 0.8534 - val_loss: 0.5640 - val_acc: 0.7317\n",
      "Epoch 29/100\n",
      "491/491 [==============================] - 0s 276us/step - loss: 0.3436 - acc: 0.8452 - val_loss: 0.5580 - val_acc: 0.7073\n",
      "Epoch 30/100\n",
      "491/491 [==============================] - 0s 297us/step - loss: 0.3324 - acc: 0.8595 - val_loss: 0.5951 - val_acc: 0.7073\n",
      "Epoch 31/100\n",
      "491/491 [==============================] - 0s 274us/step - loss: 0.3303 - acc: 0.8615 - val_loss: 0.5815 - val_acc: 0.7154\n",
      "Epoch 32/100\n",
      "491/491 [==============================] - 0s 285us/step - loss: 0.3305 - acc: 0.8554 - val_loss: 0.5740 - val_acc: 0.7317\n",
      "Epoch 33/100\n",
      "491/491 [==============================] - 0s 278us/step - loss: 0.3287 - acc: 0.8717 - val_loss: 0.6164 - val_acc: 0.6829\n",
      "Epoch 34/100\n",
      "491/491 [==============================] - 0s 306us/step - loss: 0.3231 - acc: 0.8717 - val_loss: 0.5716 - val_acc: 0.7317\n",
      "Epoch 35/100\n",
      "491/491 [==============================] - 0s 288us/step - loss: 0.3221 - acc: 0.8635 - val_loss: 0.6015 - val_acc: 0.7073\n",
      "Epoch 36/100\n",
      "491/491 [==============================] - 0s 310us/step - loss: 0.3134 - acc: 0.8758 - val_loss: 0.5746 - val_acc: 0.7073\n",
      "Epoch 37/100\n",
      "491/491 [==============================] - 0s 274us/step - loss: 0.3161 - acc: 0.8615 - val_loss: 0.6320 - val_acc: 0.7154\n",
      "Epoch 38/100\n",
      "491/491 [==============================] - 0s 271us/step - loss: 0.3134 - acc: 0.8697 - val_loss: 0.6186 - val_acc: 0.7236\n",
      "Epoch 39/100\n",
      "491/491 [==============================] - 0s 268us/step - loss: 0.3109 - acc: 0.8697 - val_loss: 0.6331 - val_acc: 0.7154\n",
      "Epoch 40/100\n",
      "491/491 [==============================] - 0s 277us/step - loss: 0.3021 - acc: 0.8717 - val_loss: 0.5711 - val_acc: 0.7236\n",
      "Epoch 41/100\n",
      "491/491 [==============================] - 0s 264us/step - loss: 0.2970 - acc: 0.8819 - val_loss: 0.6464 - val_acc: 0.6992\n",
      "Epoch 42/100\n",
      "491/491 [==============================] - 0s 265us/step - loss: 0.2920 - acc: 0.8859 - val_loss: 0.6313 - val_acc: 0.7398\n",
      "Epoch 43/100\n",
      "491/491 [==============================] - 0s 272us/step - loss: 0.2896 - acc: 0.8798 - val_loss: 0.6165 - val_acc: 0.7154\n",
      "Epoch 44/100\n",
      "491/491 [==============================] - 0s 256us/step - loss: 0.2865 - acc: 0.8819 - val_loss: 0.6600 - val_acc: 0.7073\n",
      "Epoch 45/100\n",
      "491/491 [==============================] - 0s 270us/step - loss: 0.2928 - acc: 0.8819 - val_loss: 0.6710 - val_acc: 0.6992\n",
      "Epoch 46/100\n",
      "491/491 [==============================] - 0s 303us/step - loss: 0.2881 - acc: 0.8778 - val_loss: 0.6700 - val_acc: 0.6829\n",
      "Epoch 47/100\n",
      "491/491 [==============================] - 0s 275us/step - loss: 0.2817 - acc: 0.8880 - val_loss: 0.6572 - val_acc: 0.7398\n",
      "Epoch 48/100\n",
      "491/491 [==============================] - 0s 265us/step - loss: 0.2750 - acc: 0.8859 - val_loss: 0.6366 - val_acc: 0.7154\n",
      "Epoch 49/100\n",
      "491/491 [==============================] - 0s 243us/step - loss: 0.2908 - acc: 0.8717 - val_loss: 0.6008 - val_acc: 0.7561\n",
      "Epoch 50/100\n",
      "491/491 [==============================] - 0s 272us/step - loss: 0.2990 - acc: 0.8697 - val_loss: 0.6419 - val_acc: 0.7398\n",
      "Epoch 51/100\n",
      "491/491 [==============================] - 0s 268us/step - loss: 0.2672 - acc: 0.8961 - val_loss: 0.6575 - val_acc: 0.7480\n",
      "Epoch 52/100\n",
      "491/491 [==============================] - 0s 258us/step - loss: 0.2645 - acc: 0.8859 - val_loss: 0.7168 - val_acc: 0.7317\n",
      "Epoch 53/100\n",
      "491/491 [==============================] - 0s 254us/step - loss: 0.2548 - acc: 0.8921 - val_loss: 0.6727 - val_acc: 0.7480\n",
      "Epoch 54/100\n",
      "491/491 [==============================] - 0s 273us/step - loss: 0.2580 - acc: 0.8982 - val_loss: 0.6434 - val_acc: 0.7398\n",
      "Epoch 55/100\n",
      "491/491 [==============================] - 0s 268us/step - loss: 0.2542 - acc: 0.8880 - val_loss: 0.6589 - val_acc: 0.7236\n",
      "Epoch 56/100\n",
      "491/491 [==============================] - 0s 259us/step - loss: 0.2488 - acc: 0.8961 - val_loss: 0.6991 - val_acc: 0.7317\n",
      "Epoch 57/100\n",
      "491/491 [==============================] - 0s 232us/step - loss: 0.2477 - acc: 0.9022 - val_loss: 0.7001 - val_acc: 0.7317\n",
      "Epoch 58/100\n",
      "491/491 [==============================] - 0s 263us/step - loss: 0.2471 - acc: 0.8900 - val_loss: 0.7001 - val_acc: 0.7561\n",
      "Epoch 59/100\n",
      "491/491 [==============================] - 0s 237us/step - loss: 0.2397 - acc: 0.8982 - val_loss: 0.7045 - val_acc: 0.7642\n",
      "Epoch 60/100\n",
      "491/491 [==============================] - 0s 265us/step - loss: 0.2206 - acc: 0.9165 - val_loss: 0.6776 - val_acc: 0.7398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "491/491 [==============================] - 0s 256us/step - loss: 0.2340 - acc: 0.9084 - val_loss: 0.6646 - val_acc: 0.7398\n",
      "Epoch 62/100\n",
      "491/491 [==============================] - 0s 199us/step - loss: 0.2313 - acc: 0.8982 - val_loss: 0.7046 - val_acc: 0.7561\n",
      "Epoch 63/100\n",
      "491/491 [==============================] - 0s 213us/step - loss: 0.2408 - acc: 0.8839 - val_loss: 0.7783 - val_acc: 0.7398\n",
      "Epoch 64/100\n",
      "491/491 [==============================] - 0s 227us/step - loss: 0.2313 - acc: 0.8880 - val_loss: 0.7429 - val_acc: 0.7561\n",
      "Epoch 65/100\n",
      "491/491 [==============================] - 0s 243us/step - loss: 0.2213 - acc: 0.9145 - val_loss: 0.7285 - val_acc: 0.7154\n",
      "Epoch 66/100\n",
      "491/491 [==============================] - 0s 226us/step - loss: 0.2136 - acc: 0.9124 - val_loss: 0.6419 - val_acc: 0.7642\n",
      "Epoch 67/100\n",
      "491/491 [==============================] - 0s 234us/step - loss: 0.2025 - acc: 0.9145 - val_loss: 0.7573 - val_acc: 0.7398\n",
      "Epoch 68/100\n",
      "491/491 [==============================] - 0s 236us/step - loss: 0.1983 - acc: 0.9246 - val_loss: 0.8152 - val_acc: 0.7398\n",
      "Epoch 69/100\n",
      "491/491 [==============================] - 0s 223us/step - loss: 0.2028 - acc: 0.9185 - val_loss: 0.7210 - val_acc: 0.7561\n",
      "Epoch 70/100\n",
      "491/491 [==============================] - 0s 240us/step - loss: 0.1974 - acc: 0.9185 - val_loss: 0.7921 - val_acc: 0.7398\n",
      "Epoch 71/100\n",
      "491/491 [==============================] - 0s 233us/step - loss: 0.1940 - acc: 0.9206 - val_loss: 0.7036 - val_acc: 0.7398\n",
      "Epoch 72/100\n",
      "491/491 [==============================] - 0s 229us/step - loss: 0.1815 - acc: 0.9348 - val_loss: 0.7419 - val_acc: 0.7398\n",
      "Epoch 73/100\n",
      "491/491 [==============================] - 0s 221us/step - loss: 0.1849 - acc: 0.9206 - val_loss: 0.8392 - val_acc: 0.7398\n",
      "Epoch 74/100\n",
      "491/491 [==============================] - 0s 232us/step - loss: 0.1751 - acc: 0.9308 - val_loss: 0.8929 - val_acc: 0.7480\n",
      "Epoch 75/100\n",
      "491/491 [==============================] - 0s 218us/step - loss: 0.1861 - acc: 0.9206 - val_loss: 0.8237 - val_acc: 0.7236\n",
      "Epoch 76/100\n",
      "491/491 [==============================] - 0s 219us/step - loss: 0.1952 - acc: 0.9246 - val_loss: 0.8097 - val_acc: 0.7317\n",
      "Epoch 77/100\n",
      "491/491 [==============================] - 0s 223us/step - loss: 0.1880 - acc: 0.9165 - val_loss: 0.7782 - val_acc: 0.7724\n",
      "Epoch 78/100\n",
      "491/491 [==============================] - 0s 246us/step - loss: 0.1701 - acc: 0.9348 - val_loss: 0.7828 - val_acc: 0.7317\n",
      "Epoch 79/100\n",
      "491/491 [==============================] - 0s 231us/step - loss: 0.1632 - acc: 0.9287 - val_loss: 0.7064 - val_acc: 0.7724\n",
      "Epoch 80/100\n",
      "491/491 [==============================] - 0s 233us/step - loss: 0.1628 - acc: 0.9369 - val_loss: 0.9242 - val_acc: 0.7236\n",
      "Epoch 81/100\n",
      "491/491 [==============================] - 0s 220us/step - loss: 0.1640 - acc: 0.9287 - val_loss: 0.8822 - val_acc: 0.7236\n",
      "Epoch 82/100\n",
      "491/491 [==============================] - 0s 206us/step - loss: 0.1799 - acc: 0.9165 - val_loss: 0.8279 - val_acc: 0.7642\n",
      "Epoch 83/100\n",
      "491/491 [==============================] - 0s 229us/step - loss: 0.1554 - acc: 0.9348 - val_loss: 0.8865 - val_acc: 0.7398\n",
      "Epoch 84/100\n",
      "491/491 [==============================] - 0s 231us/step - loss: 0.1552 - acc: 0.9369 - val_loss: 0.8513 - val_acc: 0.7154\n",
      "Epoch 85/100\n",
      "491/491 [==============================] - 0s 226us/step - loss: 0.1443 - acc: 0.9409 - val_loss: 0.8684 - val_acc: 0.7398\n",
      "Epoch 86/100\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.1859 - acc: 0.9226 - val_loss: 0.8628 - val_acc: 0.7398\n",
      "Epoch 87/100\n",
      "491/491 [==============================] - 0s 214us/step - loss: 0.1783 - acc: 0.9084 - val_loss: 0.9821 - val_acc: 0.7398\n",
      "Epoch 88/100\n",
      "491/491 [==============================] - 0s 237us/step - loss: 0.1471 - acc: 0.9450 - val_loss: 0.8313 - val_acc: 0.7236\n",
      "Epoch 89/100\n",
      "491/491 [==============================] - 0s 233us/step - loss: 0.1365 - acc: 0.9430 - val_loss: 0.8945 - val_acc: 0.7724\n",
      "Epoch 90/100\n",
      "491/491 [==============================] - 0s 231us/step - loss: 0.1285 - acc: 0.9491 - val_loss: 0.9100 - val_acc: 0.7561\n",
      "Epoch 91/100\n",
      "491/491 [==============================] - 0s 238us/step - loss: 0.1278 - acc: 0.9593 - val_loss: 0.7954 - val_acc: 0.7561\n",
      "Epoch 92/100\n",
      "491/491 [==============================] - 0s 225us/step - loss: 0.1227 - acc: 0.9572 - val_loss: 0.9395 - val_acc: 0.7398\n",
      "Epoch 93/100\n",
      "491/491 [==============================] - 0s 236us/step - loss: 0.1181 - acc: 0.9491 - val_loss: 0.9191 - val_acc: 0.7561\n",
      "Epoch 94/100\n",
      "491/491 [==============================] - 0s 235us/step - loss: 0.1180 - acc: 0.9491 - val_loss: 0.9387 - val_acc: 0.7480\n",
      "Epoch 95/100\n",
      "491/491 [==============================] - 0s 214us/step - loss: 0.1115 - acc: 0.9593 - val_loss: 0.9500 - val_acc: 0.7805\n",
      "Epoch 96/100\n",
      "491/491 [==============================] - 0s 223us/step - loss: 0.1088 - acc: 0.9654 - val_loss: 0.9053 - val_acc: 0.7317\n",
      "Epoch 97/100\n",
      "491/491 [==============================] - 0s 230us/step - loss: 0.1088 - acc: 0.9532 - val_loss: 0.8981 - val_acc: 0.7561\n",
      "Epoch 98/100\n",
      "491/491 [==============================] - 0s 223us/step - loss: 0.1002 - acc: 0.9552 - val_loss: 0.8862 - val_acc: 0.7398\n",
      "Epoch 99/100\n",
      "491/491 [==============================] - 0s 243us/step - loss: 0.0952 - acc: 0.9674 - val_loss: 0.9285 - val_acc: 0.7561\n",
      "Epoch 100/100\n",
      "491/491 [==============================] - 0s 238us/step - loss: 0.0953 - acc: 0.9674 - val_loss: 0.8348 - val_acc: 0.7561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefc0544b70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10)\n",
    "classifier.fit(x_train, y_train,validation_split=0.2, batch_size=20, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = [[1, 189, 60, 23, 846, 30.1, 0.398, 59], [3, 88, 58, 11, 54, 24.8, 0.267, 22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89870775],\n",
       "       [ 0.16087674]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = classifier.predict(sc.fit_transform(x_new))\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_result = ['positive' if i > 0.5 else 'negative' for i in y_new ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'negative']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80, 20],\n",
       "       [18, 36]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_pred = y_pred > 0.5\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  75.3246753247%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "print(\"Accuracy: \", str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  75.3246753247\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_pred, y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
